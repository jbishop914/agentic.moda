// Document Processing Engine - The Heart of UltraQuery
// Handles PDF, OCR, metadata extraction, and content analysis

use crate::types::*;
use chrono::Utc;
use pdf_extract::extract_text;
use std::fs;
use std::path::Path;
use uuid::Uuid;
use tracing::{info, warn, error};
use regex::Regex;
use std::collections::HashMap;
use scraper::{Html, Selector};

pub struct DocumentProcessor {
    // OCR engine for scanned PDFs
    tesseract_config: TesseractConfig,
    // Text processing patterns
    entity_patterns: EntityPatterns,
}

struct TesseractConfig {
    language: String,
    confidence_threshold: u8,
}

struct EntityPatterns {
    email_pattern: Regex,
    phone_pattern: Regex,
    date_pattern: Regex,
    money_pattern: Regex,
    person_pattern: Regex,
    company_pattern: Regex,
}

impl DocumentProcessor {
    pub fn new() -> Self {
        info!("ü¶Ä Initializing Document Processor...");
        
        Self {
            tesseract_config: TesseractConfig {
                language: "eng".to_string(),
                confidence_threshold: 60,
            },
            entity_patterns: EntityPatterns::new(),
        }
    }

    /// Main entry point for LIGHTNING FAST document processing ‚ö°
    pub async fn process_document(&self, file_path: &str) -> Result<ProcessedDocument, ProcessingError> {
        let processing_start = std::time::Instant::now();
        info!("‚ö° FAST processing started: {}", file_path);
        
        let path = Path::new(file_path);
        if !path.exists() {
            return Err(ProcessingError::FileNotFound(file_path.to_string()));
        }

        // Determine document type
        let doc_type = self.determine_document_type(file_path)?;
        
        // Extract content based on type
        let content = match doc_type {
            DocumentType::PDF => self.process_pdf(file_path).await?,
            DocumentType::Word => self.process_word(file_path).await?,
            DocumentType::Excel => self.process_excel(file_path).await?,
            DocumentType::Email => self.process_email(file_path).await?,
            DocumentType::PlainText => self.process_text(file_path).await?,
            DocumentType::Image => self.process_image_ocr(file_path).await?,
            DocumentType::Html => self.process_html(file_path).await?,
            DocumentType::Xml => self.process_xml(file_path).await?,
        };

        // Extract metadata
        let metadata = self.extract_metadata(file_path, &doc_type).await?;

        // Extract entities and relationships
        let entities = self.extract_entities(&content.raw_text);
        let relationships = self.build_relationships(&entities, file_path);

        // Build search index
        let search_index = self.build_search_index(&content, &entities, &metadata);

        // Create processed document
        let processed_doc = ProcessedDocument {
            id: Uuid::new_v4(),
            original_filename: path.file_name()
                .unwrap_or_default()
                .to_string_lossy()
                .to_string(),
            file_path: file_path.to_string(),
            file_type: doc_type,
            processed_at: Utc::now(),
            content,
            metadata,
            relationships,
            search_index,
        };

        let total_time = processing_start.elapsed();
        info!("‚ö° BLAZING FAST document processed: {} entities in {}ms", 
            entities.len(), total_time.as_millis());
        Ok(processed_doc)
    }

    /// Process PDF files (digital + OCR)
    async fn process_pdf(&self, file_path: &str) -> Result<ExtractedContent, ProcessingError> {
        info!("üìñ Processing PDF: {}", file_path);
        
        // Try digital text extraction first
        let raw_text = match extract_text(file_path) {
            Ok(text) => {
                info!("‚úÖ Digital text extracted: {} characters", text.len());
                text
            }
            Err(_) => {
                warn!("‚ùå Digital extraction failed, OCR fallback disabled");
                format!("Failed to extract text from PDF: {}", file_path)
            }
        };

        // If digital extraction yielded very little text, try OCR as well
        // (OCR functionality commented out - requires tesseract system libraries)
        if raw_text.len() < 100 {
            warn!("üîç Low text yield detected, OCR enhancement disabled for now");
        }

        // Extract structured data from PDF
        let structured_data = self.extract_pdf_structure(&raw_text, file_path).await?;

        // Extract images for potential OCR
        let images = self.extract_pdf_images(file_path).await?;

        Ok(ExtractedContent {
            raw_text,
            structured_data: Some(structured_data),
            images,
            attachments: Vec::new(),
        })
    }

    /// OCR processing for scanned PDFs and images (disabled)
    #[allow(dead_code)]
    async fn extract_text_with_ocr(&self, file_path: &str) -> Result<String, ProcessingError> {
        info!("üîç OCR processing disabled for: {}", file_path);
        
        // OCR functionality disabled - requires tesseract system libraries
        let ocr_text = format!("OCR_PROCESSING_DISABLED_FOR_{}", 
            Path::new(file_path).file_name().unwrap().to_string_lossy());
        
        Ok(ocr_text)
    }

    /// Extract structured data from PDF content
    async fn extract_pdf_structure(&self, text: &str, _file_path: &str) -> Result<StructuredData, ProcessingError> {
        // Extract tables, lists, headers, signatures
        let tables = self.extract_tables(text);
        let lists = self.extract_lists(text);
        let headers = self.extract_headers(text);
        let signatures = self.extract_signatures(text);

        Ok(StructuredData {
            tables,
            lists,
            headers,
            signatures,
        })
    }

    /// Extract images from PDF for OCR processing
    async fn extract_pdf_images(&self, _file_path: &str) -> Result<Vec<ExtractedImage>, ProcessingError> {
        // In a real implementation, this would extract images using lopdf
        // For now, return empty vector
        Ok(Vec::new())
    }

    /// Process Word documents
    async fn process_word(&self, file_path: &str) -> Result<ExtractedContent, ProcessingError> {
        info!("üìù Processing Word document: {}", file_path);
        
        // Placeholder for Word processing using docx-rs
        let raw_text = format!("WORD_DOCUMENT_CONTENT_FROM_{}", 
            Path::new(file_path).file_name().unwrap().to_string_lossy());
        
        Ok(ExtractedContent {
            raw_text,
            structured_data: None,
            images: Vec::new(),
            attachments: Vec::new(),
        })
    }

    /// Process Excel files
    async fn process_excel(&self, file_path: &str) -> Result<ExtractedContent, ProcessingError> {
        info!("üìä Processing Excel file: {}", file_path);
        
        // Placeholder for Excel processing using calamine
        let raw_text = format!("EXCEL_DATA_FROM_{}", 
            Path::new(file_path).file_name().unwrap().to_string_lossy());
        
        Ok(ExtractedContent {
            raw_text,
            structured_data: None,
            images: Vec::new(),
            attachments: Vec::new(),
        })
    }

    /// Process email files
    async fn process_email(&self, file_path: &str) -> Result<ExtractedContent, ProcessingError> {
        info!("üìß Processing email: {}", file_path);
        
        // Placeholder for email processing using mailparse
        let raw_text = format!("EMAIL_CONTENT_FROM_{}", 
            Path::new(file_path).file_name().unwrap().to_string_lossy());
        
        Ok(ExtractedContent {
            raw_text,
            structured_data: None,
            images: Vec::new(),
            attachments: Vec::new(),
        })
    }

    /// Process plain text files
    async fn process_text(&self, file_path: &str) -> Result<ExtractedContent, ProcessingError> {
        info!("üìÑ Processing text file: {}", file_path);
        
        let raw_text = fs::read_to_string(file_path)
            .map_err(|e| ProcessingError::IoError(e.to_string()))?;
        
        Ok(ExtractedContent {
            raw_text,
            structured_data: None,
            images: Vec::new(),
            attachments: Vec::new(),
        })
    }

    /// Process image files with OCR (disabled for now)
    async fn process_image_ocr(&self, file_path: &str) -> Result<ExtractedContent, ProcessingError> {
        info!("üñºÔ∏è Processing image (OCR disabled): {}", file_path);
        
        let raw_text = format!("IMAGE_FILE_DETECTED: {} (OCR processing disabled)", file_path);
        
        Ok(ExtractedContent {
            raw_text,
            structured_data: None,
            images: Vec::new(),
            attachments: Vec::new(),
        })
    }

    /// Process HTML files (SEC filings are often in HTML format) - LIGHTNING FAST ‚ö°
    async fn process_html(&self, file_path: &str) -> Result<ExtractedContent, ProcessingError> {
        info!("‚ö° FAST processing HTML: {}", file_path);
        
        let html_content = fs::read_to_string(file_path)
            .map_err(|e| ProcessingError::IoError(e.to_string()))?;

        // Parse HTML and extract clean text
        let document = Html::parse_document(&html_content);
        let text_selector = Selector::parse("body").unwrap_or_else(|_| {
            Selector::parse("*").unwrap() // Fallback to all elements
        });
        
        let raw_text = document.select(&text_selector)
            .map(|element| element.text().collect::<Vec<_>>().join(" "))
            .collect::<Vec<_>>()
            .join("\n");
        
        // If we got no text, fall back to stripping HTML tags
        let raw_text = if raw_text.trim().is_empty() {
            regex::Regex::new(r"<[^>]*>").unwrap()
                .replace_all(&html_content, " ")
                .to_string()
        } else {
            raw_text
        };

        // Clean up whitespace
        let cleaned_text = regex::Regex::new(r"\s+").unwrap()
            .replace_all(&raw_text, " ")
            .trim()
            .to_string();

        info!("‚úÖ HTML processed: {} characters extracted", cleaned_text.len());

        Ok(ExtractedContent {
            raw_text: cleaned_text,
            structured_data: None,
            images: Vec::new(),
            attachments: Vec::new(),
        })
    }

    /// Process XML files (XBRL and other SEC formats) - BLAZING FAST ‚ö°
    async fn process_xml(&self, file_path: &str) -> Result<ExtractedContent, ProcessingError> {
        info!("‚ö° FAST processing XML: {}", file_path);
        
        let xml_content = fs::read_to_string(file_path)
            .map_err(|e| ProcessingError::IoError(e.to_string()))?;

        // Extract text content from XML by removing tags
        let raw_text = regex::Regex::new(r"<[^>]*>").unwrap()
            .replace_all(&xml_content, " ")
            .to_string();

        // Clean up whitespace and common XML entities
        let cleaned_text = raw_text
            .replace("&nbsp;", " ")
            .replace("&amp;", "&")
            .replace("&lt;", "<")
            .replace("&gt;", ">")
            .replace("&quot;", "\"");

        let final_text = regex::Regex::new(r"\s+").unwrap()
            .replace_all(&cleaned_text, " ")
            .trim()
            .to_string();

        info!("‚úÖ XML processed: {} characters extracted", final_text.len());

        Ok(ExtractedContent {
            raw_text: final_text,
            structured_data: None,
            images: Vec::new(),
            attachments: Vec::new(),
        })
    }

    /// Determine document type from file extension
    fn determine_document_type(&self, file_path: &str) -> Result<DocumentType, ProcessingError> {
        let path = Path::new(file_path);
        let extension = path.extension()
            .and_then(|ext| ext.to_str())
            .unwrap_or("")
            .to_lowercase();

        match extension.as_str() {
            "pdf" => Ok(DocumentType::PDF),
            "doc" | "docx" => Ok(DocumentType::Word),
            "xls" | "xlsx" => Ok(DocumentType::Excel),
            "eml" | "msg" => Ok(DocumentType::Email),
            "txt" | "md" => Ok(DocumentType::PlainText),
            "png" | "jpg" | "jpeg" | "tiff" | "bmp" => Ok(DocumentType::Image),
            "html" | "htm" => Ok(DocumentType::Html),
            "xml" => Ok(DocumentType::Xml),
            _ => Err(ProcessingError::UnsupportedFileType(extension)),
        }
    }

    /// Extract document metadata
    async fn extract_metadata(&self, file_path: &str, _doc_type: &DocumentType) -> Result<DocumentMetadata, ProcessingError> {
        let metadata = fs::metadata(file_path)
            .map_err(|e| ProcessingError::IoError(e.to_string()))?;

        Ok(DocumentMetadata {
            file_size: metadata.len(),
            created_date: metadata.created().ok().map(|t| t.into()),
            modified_date: metadata.modified().ok().map(|t| t.into()),
            author: None, // Will be extracted from document properties
            title: None,
            subject: None,
            keywords: Vec::new(),
            language: Some("en".to_string()),
            page_count: None,
            custom_properties: HashMap::new(),
        })
    }

    /// Extract entities from text using patterns
    fn extract_entities(&self, text: &str) -> Vec<Entity> {
        let mut entities = Vec::new();

        // Extract emails
        for mat in self.entity_patterns.email_pattern.find_iter(text) {
            entities.push(Entity {
                entity_type: EntityType::Email,
                value: mat.as_str().to_string(),
                positions: vec![Position {
                    page: None,
                    x: None,
                    y: None,
                    width: None,
                    height: None,
                }],
            });
        }

        // Extract phone numbers
        for mat in self.entity_patterns.phone_pattern.find_iter(text) {
            entities.push(Entity {
                entity_type: EntityType::PhoneNumber,
                value: mat.as_str().to_string(),
                positions: vec![Position {
                    page: None,
                    x: None,
                    y: None,
                    width: None,
                    height: None,
                }],
            });
        }

        // Extract money amounts
        for mat in self.entity_patterns.money_pattern.find_iter(text) {
            entities.push(Entity {
                entity_type: EntityType::Money,
                value: mat.as_str().to_string(),
                positions: vec![Position {
                    page: None,
                    x: None,
                    y: None,
                    width: None,
                    height: None,
                }],
            });
        }

        entities
    }

    /// Build relationships between entities
    fn build_relationships(&self, entities: &[Entity], file_path: &str) -> Vec<Relationship> {
        let mut relationships = Vec::new();

        // Example: Link entities found in the same document
        for (i, entity1) in entities.iter().enumerate() {
            for entity2 in entities.iter().skip(i + 1) {
                if self.entities_are_related(entity1, entity2) {
                    relationships.push(Relationship {
                        relationship_type: RelationshipType::DocumentToDocument,
                        source_entity: entity1.clone(),
                        target_entity: entity2.clone(),
                        confidence: 0.8,
                        context: format!("Found together in {}", file_path),
                    });
                }
            }
        }

        relationships
    }

    /// Check if entities are related (simple heuristic)
    fn entities_are_related(&self, _entity1: &Entity, _entity2: &Entity) -> bool {
        // Placeholder logic - in reality, this would use more sophisticated analysis
        true
    }

    /// Build search index for fast retrieval
    fn build_search_index(&self, content: &ExtractedContent, entities: &[Entity], _metadata: &DocumentMetadata) -> SearchIndex {
        let keywords = self.extract_keywords(&content.raw_text);
        let semantic_chunks = self.create_semantic_chunks(&content.raw_text);

        SearchIndex {
            keywords,
            entities: entities.to_vec(),
            semantic_chunks,
            full_text_searchable: content.raw_text.to_lowercase(),
        }
    }

    /// Extract important keywords from text
    fn extract_keywords(&self, text: &str) -> Vec<String> {
        // Simple keyword extraction - in reality, use TF-IDF or more advanced methods
        text.split_whitespace()
            .filter(|word| word.len() > 3)
            .take(50)
            .map(|word| word.to_lowercase())
            .collect()
    }

    /// Create semantic chunks for AI processing
    fn create_semantic_chunks(&self, text: &str) -> Vec<SemanticChunk> {
        // Split text into paragraphs and create chunks
        text.split("\n\n")
            .enumerate()
            .map(|(i, paragraph)| SemanticChunk {
                id: Uuid::new_v4(),
                text: paragraph.to_string(),
                chunk_type: ChunkType::Paragraph,
                position: Position {
                    page: Some(1),
                    x: None,
                    y: Some(i as f32 * 20.0),
                    width: None,
                    height: None,
                },
                summary: None,
            })
            .collect()
    }

    // Structured data extraction methods
    fn extract_tables(&self, _text: &str) -> Vec<Table> {
        // Placeholder for table extraction
        Vec::new()
    }

    fn extract_lists(&self, _text: &str) -> Vec<List> {
        // Placeholder for list extraction
        Vec::new()
    }

    fn extract_headers(&self, _text: &str) -> Vec<Header> {
        // Placeholder for header extraction
        Vec::new()
    }

    fn extract_signatures(&self, _text: &str) -> Vec<Signature> {
        // Placeholder for signature extraction
        Vec::new()
    }
}

impl EntityPatterns {
    fn new() -> Self {
        Self {
            email_pattern: Regex::new(r"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b").unwrap(),
            phone_pattern: Regex::new(r"\b\d{3}[-.]?\d{3}[-.]?\d{4}\b").unwrap(),
            date_pattern: Regex::new(r"\b\d{1,2}/\d{1,2}/\d{4}\b").unwrap(),
            money_pattern: Regex::new(r"\$\d+(?:,\d{3})*(?:\.\d{2})?").unwrap(),
            person_pattern: Regex::new(r"\b[A-Z][a-z]+ [A-Z][a-z]+\b").unwrap(),
            company_pattern: Regex::new(r"\b[A-Z][a-zA-Z0-9\s]+ (?:Inc|LLC|Corp|Ltd)\.?\b").unwrap(),
        }
    }
}

#[derive(Debug, thiserror::Error)]
pub enum ProcessingError {
    #[error("File not found: {0}")]
    FileNotFound(String),
    
    #[error("Unsupported file type: {0}")]
    UnsupportedFileType(String),
    
    #[error("IO error: {0}")]
    IoError(String),
    
    #[error("OCR processing failed: {0}")]
    OcrError(String),
    
    #[error("PDF processing failed: {0}")]
    PdfError(String),
}